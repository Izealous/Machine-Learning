{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d9dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5d284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Dataset\n",
    "dataset = pd.read_csv('hasilpreproces_balance.csv', delimiter = ';', quoting = 3)\n",
    "corpus = dataset['text'].tolist()\n",
    "# corpus = ['suka tidak bisa sesuai tingkat bawa rasa',\n",
    "#           'tidak usah alas guna tidak tahu sopan santun',\n",
    "#           'suka sama sini tampar',\n",
    "#          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91cc9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a7cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59722222 0.60555556 0.73888889 0.8        0.81944444 0.87222222\n",
      " 0.88055556 0.79166667 0.78333333 0.69444444]\n",
      "Rata - Rata Akurasi :  0.7583333333333334\n"
     ]
    }
   ],
   "source": [
    "#Cross Val NBC\n",
    "classifierNB = MultinomialNB()\n",
    "cv_nb = cross_val_score(classifierNB, x, y, cv = 10)\n",
    "print(cv_nb)\n",
    "print(\"Rata - Rata Akurasi : \",mean(cv_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5740c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44722222 0.45277778 0.56666667 0.74722222 0.78333333 0.82222222\n",
      " 0.85833333 0.73888889 0.75       0.32222222]\n",
      "Rata - Rata Akurasi :  0.6488888888888888\n"
     ]
    }
   ],
   "source": [
    "#Cross Val Adaboost NBC\n",
    "classifierBoost = AdaBoostClassifier(base_estimator = classifierNB,)\n",
    "cv_ada = cross_val_score(classifierBoost, x, y, cv = 10)\n",
    "print(cv_ada)\n",
    "print(\"Rata - Rata Akurasi : \",mean(cv_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d072789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7abf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klasifikasi Data NBC\n",
    "classifierNB.fit(x_train, y_train)\n",
    "data_pred = classifierNB.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e86e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Data Real Naive Bayes :\n",
      "\n",
      " [[1130   15   55]\n",
      " [  50 1108   42]\n",
      " [  57    0 1143]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix Data NBC\n",
    "cm_Dnb = confusion_matrix(y, data_pred)\n",
    "print('Confusion Matrix Data Real Naive Bayes :\\n\\n', cm_Dnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a66105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Confusion Matrix Data Real Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.94      0.93      1200\n",
      "           0       0.99      0.92      0.95      1200\n",
      "           1       0.92      0.95      0.94      1200\n",
      "\n",
      "    accuracy                           0.94      3600\n",
      "   macro avg       0.94      0.94      0.94      3600\n",
      "weighted avg       0.94      0.94      0.94      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Nilai Data Confusion Matrix NBC\n",
    "score_Dnb = classification_report(y, data_pred, zero_division=0)\n",
    "print('Score Confusion Matrix Data Real Naive Bayes :\\n\\n', score_Dnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a494cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klasifikasi Data Adaboost NBC\n",
    "classifierBoost.fit(x_train, y_train)\n",
    "Dpred_boost = classifierBoost.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8008ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Data Real Adaboost Naive Bayes :\n",
      "\n",
      " [[1079   81   40]\n",
      " [ 396  800    4]\n",
      " [ 643    1  556]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix Test Adaboost NBC\n",
    "cm_Dad = confusion_matrix(y, Dpred_boost)\n",
    "print('Confusion Matrix Data Real Adaboost Naive Bayes :\\n\\n', cm_Dad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9196af13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Confusion Matrix Data Real Adaboost Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.90      0.65      1200\n",
      "           0       0.91      0.67      0.77      1200\n",
      "           1       0.93      0.46      0.62      1200\n",
      "\n",
      "    accuracy                           0.68      3600\n",
      "   macro avg       0.78      0.68      0.68      3600\n",
      "weighted avg       0.78      0.68      0.68      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Nilai Data Confusion Matrix Adaboost NBC\n",
    "score_Dad =classification_report(y,Dpred_boost, zero_division=0)\n",
    "print('Score Confusion Matrix Data Real Adaboost Naive Bayes :\\n\\n', score_Dad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c78646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
